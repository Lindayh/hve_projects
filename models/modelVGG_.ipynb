{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pandas numpy scikit-learn plotly matplotlib\n",
    "# ! pip install nbformat\n",
    "# ! pip install --upgrade nbformat\n",
    "# ! pip install tensorflow[and-cuda]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 13:05:58.894489: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-30 13:05:58.906491: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-30 13:05:58.910084: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-30 13:05:58.919821: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-30 13:05:59.678338: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'visualkeras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Precision, Recall, F1Score\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m regularizers\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mvisualkeras\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'visualkeras'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datetime import datetime as dt\n",
    "import glob\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.keras.applications import VGG16, VGG19\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Rescaling, Conv2D, MaxPooling2D, Flatten, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, SparseCategoricalCrossentropy \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.metrics import Precision, Recall, F1Score\n",
    "from tensorflow.keras import regularizers\n",
    "import visualkeras\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPUs are available for training \n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER_TRAIN = '../CIFAKE/train'\n",
    "DATASET_FOLDER_TEST = '../CIFAKE/test'\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "COLOR_MODE = 'rgb'\n",
    "CLASS_MODE = 'binary'\n",
    "TARGET_SIZE = (32, 32)\n",
    "LEARN_RATE = 0.0005\n",
    "LEARN_RATE = 0.005\n",
    "SEED = 42\n",
    "\n",
    "LOSS_FN = BinaryCrossentropy()\n",
    "\n",
    "N_EPOCHS = 50    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(   \n",
    "    rescale=1./255,  \n",
    "    # rotation_range=45,\n",
    "    # width_shift_range=0.5,\n",
    "    # height_shift_range=0.5,\n",
    "    # zoom_range=0.5,\n",
    "    # horizontal_flip=True,  \n",
    "    # vertical_flip=True,  \n",
    "    validation_split=0.2,  \n",
    ")\n",
    "\n",
    "# Load training data from directory and apply transformations\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    DATASET_FOLDER_TRAIN,  \n",
    "    target_size=TARGET_SIZE,    \n",
    "    color_mode=COLOR_MODE,  \n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=CLASS_MODE,  \n",
    "    subset='training', \n",
    "    seed = SEED\n",
    ")\n",
    "\n",
    "# Load validation data (20% of the training data)\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    DATASET_FOLDER_TRAIN, \n",
    "    target_size=TARGET_SIZE,\n",
    "    color_mode=COLOR_MODE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=CLASS_MODE,\n",
    "    subset='validation', \n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    DATASET_FOLDER_TEST,  \n",
    "    target_size=TARGET_SIZE,\n",
    "    color_mode=COLOR_MODE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=CLASS_MODE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Class distribution: ')\n",
    "print( f'Train REAL images: {len(glob.glob('../CIFAKE/train/REAL/*'))}'  )\n",
    "print( f'Train FAKE images: {len(glob.glob('../CIFAKE/train/FAKE/*'))}'  )\n",
    "\n",
    "print( f'Test REAL images: {len(glob.glob('../CIFAKE/test/REAL/*'))}'  )\n",
    "print( f'Test FAKE images: {len(glob.glob('../CIFAKE/test/FAKE/*'))}'  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show random image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to rgb\n",
    "def convert_grayscale_to_rgb(batch):\n",
    "    tensor_batch = tf.convert_to_tensor(batch)\n",
    "\n",
    "    rgb_batch = tf.image.grayscale_to_rgb(tensor_batch)\n",
    "    return rgb_batch\n",
    "\n",
    "def rgb_wrapper(generator):\n",
    "    for batch, labels in generator:\n",
    "        yield convert_grayscale_to_rgb(batch), labels\n",
    "\n",
    "train_generator_rgb = rgb_wrapper(train_generator)\n",
    "validation_generator_rgb = rgb_wrapper(validation_generator)\n",
    "test_generator_rgb = rgb_wrapper(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_layers_text = \"x = Flatten()(VGG_model.output)<br>\"\n",
    "top_layers_text += \"x = Dense(32, activation='relu')(x)<br>\"\n",
    "# top_layers_text += \"x = BatchNormalization()(x)<br>\"\n",
    "top_layers_text += \"x = Dense(32, activation='relu')(x)<br>\"\n",
    "top_layers_text += \"x = Dense(1, activation='softmax')(x)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Transfer Learning model using VGG16\n",
    "VGG_base_model = tf.keras.applications.VGG16(\n",
    "    include_top = False, \n",
    "    weights = 'imagenet', \n",
    "    input_shape = (32,32, 3),\n",
    "    pooling = 'max'\n",
    ")\n",
    "VGG_base_model.trainable = True\n",
    "\n",
    "# Create a new model on top of the VGG16 base\n",
    "inputs = tf.keras.Input(shape = (32,32, 3))\n",
    "x = VGG_base_model(inputs, training = False)\n",
    "\n",
    "x = BatchNormalization(axis = -1, momentum = 0.99, epsilon = 0.001)(x)\n",
    "x = Dense(256, \n",
    "          kernel_regularizer = regularizers.l2(0.01), \n",
    "          activity_regularizer = regularizers.l1(0.01), \n",
    "          bias_regularizer = regularizers.l1(0.01),\n",
    "          activation = 'relu')(x)\n",
    "x = Dropout(rate = .4, seed = 512)(x)       \n",
    "x = Dense(64, activation = 'relu')(x)\n",
    "\n",
    "outputs = Dense(1, activation = 'sigmoid')(x)\n",
    "VGG_model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the Transfer Learning model\n",
    "VGG_model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adamax(learning_rate = .001),\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics = ['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "# Build the Transfer Learning model so we can see a summary\n",
    "VGG_model.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = VGG_model.fit(train_generator, \n",
    "                             callbacks=[EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)],\n",
    "                             epochs=1, \n",
    "                             validation_data=validation_generator,\n",
    "                             steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "                             validation_steps=validation_generator.samples // BATCH_SIZE,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history.history\n",
    "cols = list(history.history.keys())\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = int(cols[3][-1])\n",
    "\n",
    "# dict_ = { 'loss' : hist['loss'],\n",
    "#          'accuracy' : hist[f'accuracy'],\n",
    "#          'precision' : hist[f'precision_{n}'],\n",
    "#          'recall' : hist[f'recall_{n}'],\n",
    "#          'val_loss' : hist['val_loss'],\n",
    "#          'val_accuracy' : hist[f'val_accuracy'],\n",
    "#          'val_precision' : hist[f'val_precision_{n}'],\n",
    "#          'val_recall' : hist[f'val_recall_{n}']\n",
    "\n",
    "# }\n",
    "# hist = pd.DataFrame(dict_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_metrics = make_subplots(rows=2, cols=2, subplot_titles=(\"Loss\", f\"Precision\", \"Accuracy\", \"Recall\"), vertical_spacing=0.07)\n",
    "\n",
    "# Loss\n",
    "fig_metrics.add_trace( go.Scatter(x=list(range(len(hist['loss']))), y=hist['loss'], mode='lines+markers', name='Train Loss'), row=1, col=1 )\n",
    "fig_metrics.add_trace( go.Scatter(x=list(range(len(hist['val_loss']))), y=hist['val_loss'], mode='lines+markers', name='Val Loss'), row=1, col=1 )\n",
    "\n",
    "# Precision\n",
    "fig_metrics.add_trace(  go.Scatter(x=list(range(len(hist['precision']))), y=hist['precision'],  mode='lines+markers', name=f'Train precision'),  row=1, col=2 )\n",
    "fig_metrics.add_trace( go.Scatter(x=list(range(len(hist['val_precision']))), y=hist['val_precision'], mode='lines+markers', name=f'Val precision'), row=1, col=2)\n",
    "\n",
    "# Accuracy\n",
    "fig_metrics.add_trace(  go.Scatter(x=list(range(len(hist['accuracy']))), y=hist['accuracy'],  mode='lines+markers', name=f'Train accuracy'),  row=2, col=1 )\n",
    "fig_metrics.add_trace( go.Scatter(x=list(range(len(hist['val_accuracy']))), y=hist['val_accuracy'], mode='lines+markers', name=f'Val accuracy'), row=2, col=1)\n",
    "\n",
    "# Recall\n",
    "fig_metrics.add_trace(  go.Scatter(x=list(range(len(hist['recall']))), y=hist['recall'],  mode='lines+markers', name=f'Train recall'),  row=2, col=2 )\n",
    "fig_metrics.add_trace( go.Scatter(x=list(range(len(hist['val_recall']))), y=hist['val_recall'], mode='lines+markers', name=f'Val recall'), row=2, col=2)\n",
    "\n",
    "# fig.update_xaxes(title_text=\"Epochs\", row=1, col=1)\n",
    "fig_metrics.update_yaxes(title_text=\"Loss\", row=1, col=1)\n",
    "fig_metrics.update_yaxes(title_text=f\"Precision\", row=1, col=2)\n",
    "fig_metrics.update_yaxes(title_text=f\"Accuracy\", row=2, col=1)\n",
    "fig_metrics.update_yaxes(title_text=f\"Recall\", row=2, col=2)\n",
    "\n",
    "fig_metrics.update_layout(\n",
    "    # title_text=\"Training and validation metrics over epochs\",\n",
    "    showlegend=True,\n",
    "    margin=dict(l=10, r=10, b=10, t=30),\n",
    "    width=1400, height=800\n",
    ")\n",
    "\n",
    "for annotation in fig_metrics['layout']['annotations']:\n",
    "    annotation['y'] = annotation['y'] + 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "test_loss, test_acc, test_prec, test_recall = VGG_model.evaluate(\n",
    "    test_generator,\n",
    "    steps=test_generator.samples // test_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = test_generator.classes\n",
    "y_pred = VGG_model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "# y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "y_true = y_true[:len(y_pred_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true.shape, y_pred_classes.shape, test_generator.class_indices.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Plotly heatmap for confusion matrix\n",
    "fig_confMatrix = go.Figure(data=go.Heatmap(\n",
    "    z=cm,\n",
    "    x= class_labels ,   # Predicted labels\n",
    "    y= class_labels,    # True labels\n",
    "    hoverongaps=False,\n",
    "    colorscale='Blues',\n",
    "    showscale=True,\n",
    "    text=cm,\n",
    "    texttemplate=\"%{text}\",\n",
    "    textfont={\"size\":15}\n",
    "))\n",
    "\n",
    "# Update layout to add labels and title\n",
    "fig_confMatrix.update_layout(\n",
    "    title='Confusion Matrix',\n",
    "    xaxis_title='Predicted Label',\n",
    "    yaxis_title='True Label',\n",
    "    width=600,\n",
    "    height=500,\n",
    ")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "# Compute ROC curve and ROC AUC\n",
    "fpr, tpr, _ = roc_curve(y_true, y_pred_classes)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve using Plotly\n",
    "fig_rocauc = go.Figure()\n",
    "\n",
    "# Add the ROC curve\n",
    "fig_rocauc.add_trace(go.Scatter(\n",
    "    x=fpr, y=tpr,\n",
    "    mode='lines',\n",
    "    line=dict(color='blue', width=2),\n",
    "    name=f'ROC curve (AUC = {roc_auc:0.2f})'\n",
    "))\n",
    "\n",
    "# Add the diagonal line (random classifier)\n",
    "fig_rocauc.add_trace(go.Scatter(\n",
    "    x=[0, 1], y=[0, 1],\n",
    "    mode='lines',\n",
    "    line=dict(color='black', dash='dash'),\n",
    "    showlegend=False,\n",
    "    hoverinfo='skip'\n",
    "))\n",
    "\n",
    "# Update layout with axis titles and legend\n",
    "fig_rocauc.update_layout(\n",
    "    title='ROC AUC for Binary Classification',\n",
    "    xaxis_title='False Positive Rate',\n",
    "    yaxis_title='True Positive Rate',\n",
    "    width=700,\n",
    "    height=600,\n",
    "    legend=dict(x=0.6, y=0.1),\n",
    "    margin=dict(l=40, r=40, t=40, b=40),)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_true, y_pred_classes, target_names=class_labels, \n",
    "                               zero_division=False,\n",
    "                               labels = [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation plots+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(hist)\n",
    "# hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=4, cols=2, \n",
    "    subplot_titles=(\"\", \"\",\n",
    "                    \"Loss\", \"Precision\", \n",
    "                    \"Accuracy\", 'Recall',\n",
    "                    'Confusion Matrix', 'ROC-AUC curve'), \n",
    "    horizontal_spacing=0.05, \n",
    "    vertical_spacing=0.05  \n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0.5], y=[0.5], \n",
    "        text=[\n",
    "            top_layers_text\n",
    "        ],\n",
    "        mode='text',\n",
    "        showlegend=False,\n",
    "    ),\n",
    "    row=1, col=1  \n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0.5], y=[0.5], \n",
    "        text=[\n",
    "            f\"Test loss: {test_loss:.4f}<br>\"\n",
    "            f\"Test accuracy: {test_acc:.4f}<br>\"\n",
    "            f\"Test precision: {test_prec:.4f}<br>\"\n",
    "            f\"Test recall: {test_recall:.4f}<br><br>\"\n",
    "            f\"ROC-AUC: {roc_auc:.4f}<br><br>\"\n",
    "            f\"Classification report<br>\"\n",
    "            f\"{report.replace('\\n','<br>')}\"\n",
    "        ],\n",
    "        mode='text',\n",
    "        showlegend=False,\n",
    "    ),\n",
    "    row=1, col=2  \n",
    ")\n",
    "\n",
    "# fig.update_layout(\n",
    "#     annotations=[dict(text=\"Model Metrics\", x=0.25, y=1.05, showarrow=False, xref=\"paper\", yref=\"paper\", font=dict(size=16))], \n",
    "# )\n",
    "\n",
    "# Hide the axes for the annotation row\n",
    "fig.update_xaxes(visible=False, row=1, col=1)\n",
    "fig.update_yaxes(visible=False, row=1, col=1)\n",
    "\n",
    "\n",
    "# Loss and Precision\n",
    "fig.add_trace(fig_metrics['data'][0], row=2, col=1)\n",
    "fig.add_trace(fig_metrics['data'][1], row=2, col=1)\n",
    "fig.add_trace(fig_metrics['data'][2], row=2, col=2)\n",
    "fig.add_trace(fig_metrics['data'][3], row=2, col=2)\n",
    "\n",
    "# Accuracy and Recall \n",
    "fig.add_trace(fig_metrics['data'][4], row=3, col=1)\n",
    "fig.add_trace(fig_metrics['data'][5], row=3, col=1)\n",
    "fig.add_trace(fig_metrics['data'][6], row=3, col=2)\n",
    "fig.add_trace(fig_metrics['data'][7], row=3, col=2)\n",
    "\n",
    "# Confusion Matrix and ROC-AUC curve \n",
    "fig.add_trace(fig_confMatrix['data'][0], row=4, col=1)\n",
    "fig.add_trace(fig_rocauc['data'][0], row=4, col=2)\n",
    "fig.add_trace(fig_rocauc['data'][1], row=4, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=400*4, \n",
    "    width=1400, \n",
    "    # title_text=f\"--- {MODEL.name} ---\",\n",
    "    showlegend=False, \n",
    "    margin=dict(l=10, r=10, t=50, b=10),  \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1  # TODO add file checking for n+1\n",
    "customVGG.save(f'{MODEL.name}_{n:02}.h5')\n",
    "customVGG.save(f'{MODEL.name}_{n:02}.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
