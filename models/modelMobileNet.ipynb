{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pandas numpy scikit-learn plotly matplotlib\n",
    "# ! pip install nbformat\n",
    "# ! pip install --upgrade nbformat\n",
    "# ! pip install tensorflow[and-cuda]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-25 10:34:52.193672: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-25 10:34:52.949244: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datetime import datetime as dt\n",
    "import glob\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV3Small\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Rescaling, Conv2D, MaxPooling2D, Flatten, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, SparseCategoricalCrossentropy \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.metrics import Precision, Recall, F1Score\n",
    "from tensorflow.keras import regularizers\n",
    "import visualkeras\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-25 10:34:54.421350: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-25 10:34:54.461390: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Check if GPUs are available for training \n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER_TRAIN = '../CIFAKE/train'\n",
    "DATASET_FOLDER_TEST = '../CIFAKE/test'\n",
    "\n",
    "BATCH_SIZE = 500\n",
    "COLOR_MODE = 'rgb'\n",
    "CLASS_MODE = 'binary'\n",
    "TARGET_SIZE = (32, 32)\n",
    "LEARN_RATE = 0.0005\n",
    "LEARN_RATE = 0.005\n",
    "SEED = 512\n",
    "\n",
    "LOSS_FN = BinaryCrossentropy()\n",
    "\n",
    "N_EPOCHS = 50    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 files belonging to 2 classes.\n",
      "Found 20000 files belonging to 2 classes.\n",
      "Training Classes:\n",
      "['FAKE', 'REAL']\n",
      "Testing Classes:\n",
      "['FAKE', 'REAL']\n"
     ]
    }
   ],
   "source": [
    "# Load the training data\n",
    "train_generator = tf.keras.utils.image_dataset_from_directory(\n",
    "  DATASET_FOLDER_TRAIN,\n",
    "  seed = 512,\n",
    "  image_size = TARGET_SIZE,\n",
    "  batch_size = BATCH_SIZE)\n",
    "\n",
    "# Load the validation data\n",
    "test_generator = tf.keras.utils.image_dataset_from_directory(\n",
    "  DATASET_FOLDER_TEST,\n",
    "  seed = 512,\n",
    "  image_size = TARGET_SIZE,\n",
    "  batch_size = BATCH_SIZE)\n",
    "\n",
    "print(\"Training Classes:\")\n",
    "class_names = train_generator.class_names\n",
    "print(class_names)\n",
    "\n",
    "print(\"Testing Classes:\")\n",
    "class_names = test_generator.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_layers_text = \"x = Flatten()(VGG_model.output)<br>\"\n",
    "top_layers_text += \"x = Dense(32, activation='relu')(x)<br>\"\n",
    "# top_layers_text += \"x = BatchNormalization()(x)<br>\"\n",
    "top_layers_text += \"x = Dense(32, activation='relu')(x)<br>\"\n",
    "top_layers_text += \"x = Dense(1, activation='softmax')(x)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_classes = train_generator.num_classes\n",
    "\n",
    "MobileNet_model_base = MobileNetV3Small(weights='imagenet', include_top=False, input_shape=(32,32,3), pooling='max')  \n",
    "\n",
    "MobileNet_model_base.trainable = True\n",
    "\n",
    "inputs = tf.keras.Input(shape = (32, 32, 3))\n",
    "x = MobileNet_model_base(inputs, training = False)\n",
    "x = BatchNormalization(axis = -1, momentum = 0.99, epsilon = 0.001)(x)\n",
    "x = Dense(256, \n",
    "          kernel_regularizer = regularizers.l2(0.01), \n",
    "          activity_regularizer = regularizers.l1(0.01), \n",
    "          bias_regularizer = regularizers.l1(0.01),\n",
    "          activation = 'relu')(x)\n",
    "x = Dropout(rate = .4, seed = 512)(x)       \n",
    "x = Dense(64, activation = 'relu')(x)\n",
    "outputs = Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "\n",
    "# Custom model\n",
    "custom_MobileNet = Model(inputs, outputs)  #,training=False)?\n",
    "\n",
    "custom_MobileNet.compile(loss=LOSS_FN, \n",
    "                  optimizer=tf.keras.optimizers.Adam(), \n",
    "                  metrics=['accuracy', Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 140ms/step - accuracy: 0.5029 - loss: 117.4848 - precision_1: 0.5074 - recall_1: 0.3273 - val_accuracy: 0.4745 - val_loss: 4.7131 - val_precision_1: 0.4445 - val_recall_1: 0.2044\n",
      "Epoch 2/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 135ms/step - accuracy: 0.5041 - loss: 3.1476 - precision_1: 0.5030 - recall_1: 0.7824 - val_accuracy: 0.5000 - val_loss: 2.9526 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 3/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 137ms/step - accuracy: 0.4997 - loss: 2.7748 - precision_1: 0.4729 - recall_1: 0.4849 - val_accuracy: 0.5095 - val_loss: 2.4829 - val_precision_1: 0.5049 - val_recall_1: 0.9826\n",
      "Epoch 4/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 134ms/step - accuracy: 0.5026 - loss: 2.3801 - precision_1: 0.5023 - recall_1: 0.6825 - val_accuracy: 0.4999 - val_loss: 2.0980 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 5/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 134ms/step - accuracy: 0.4997 - loss: 2.0100 - precision_1: 0.4808 - recall_1: 0.4535 - val_accuracy: 0.4982 - val_loss: 1.7461 - val_precision_1: 0.0909 - val_recall_1: 4.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 131ms/step - accuracy: 0.4972 - loss: 1.6713 - precision_1: 0.4671 - recall_1: 0.4131 - val_accuracy: 0.4999 - val_loss: 1.5122 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 7/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 130ms/step - accuracy: 0.4970 - loss: 1.5280 - precision_1: 0.4858 - recall_1: 0.5832 - val_accuracy: 0.5000 - val_loss: 1.2695 - val_precision_1: 0.5000 - val_recall_1: 1.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 132ms/step - accuracy: 0.5005 - loss: 1.2205 - precision_1: 0.5003 - recall_1: 0.6331 - val_accuracy: 0.5000 - val_loss: 1.0839 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = custom_MobileNet.fit(train_generator, \n",
    "                             callbacks=[EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)],\n",
    "                             epochs=N_EPOCHS, \n",
    "                             validation_data=test_generator\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'loss',\n",
       " 'precision_1',\n",
       " 'recall_1',\n",
       " 'val_accuracy',\n",
       " 'val_loss',\n",
       " 'val_precision_1',\n",
       " 'val_recall_1']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = history.history\n",
    "cols = list(history.history.keys())\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = int(cols[3][-1])\n",
    "\n",
    "# dict_ = { 'loss' : hist['loss'],\n",
    "#          'accuracy' : hist[f'accuracy'],\n",
    "#          'precision' : hist[f'precision_{n}'],\n",
    "#          'recall' : hist[f'recall_{n}'],\n",
    "#          'val_loss' : hist['val_loss'],\n",
    "#          'val_accuracy' : hist[f'val_accuracy'],\n",
    "#          'val_precision' : hist[f'val_precision_{n}'],\n",
    "#          'val_recall' : hist[f'val_recall_{n}']\n",
    "\n",
    "# }\n",
    "# hist = pd.DataFrame(dict_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'precision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m fig_metrics\u001b[38;5;241m.\u001b[39madd_trace( go\u001b[38;5;241m.\u001b[39mScatter(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(hist[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]))), y\u001b[38;5;241m=\u001b[39mhist[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlines+markers\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal Loss\u001b[39m\u001b[38;5;124m'\u001b[39m), row\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Precision\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m fig_metrics\u001b[38;5;241m.\u001b[39madd_trace(  go\u001b[38;5;241m.\u001b[39mScatter(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mhist\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m))), y\u001b[38;5;241m=\u001b[39mhist[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m],  mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlines+markers\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain precision\u001b[39m\u001b[38;5;124m'\u001b[39m),  row\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m )\n\u001b[1;32m      9\u001b[0m fig_metrics\u001b[38;5;241m.\u001b[39madd_trace( go\u001b[38;5;241m.\u001b[39mScatter(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(hist[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_precision\u001b[39m\u001b[38;5;124m'\u001b[39m]))), y\u001b[38;5;241m=\u001b[39mhist[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_precision\u001b[39m\u001b[38;5;124m'\u001b[39m], mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlines+markers\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal precision\u001b[39m\u001b[38;5;124m'\u001b[39m), row\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Accuracy\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'precision'"
     ]
    }
   ],
   "source": [
    "fig_metrics = make_subplots(rows=2, cols=2, subplot_titles=(\"Loss\", f\"Precision\", \"Accuracy\", \"Recall\"), vertical_spacing=0.07)\n",
    "\n",
    "# Loss\n",
    "fig_metrics.add_trace( go.Scatter(x=list(range(len(hist['loss']))), y=hist['loss'], mode='lines+markers', name='Train Loss'), row=1, col=1 )\n",
    "fig_metrics.add_trace( go.Scatter(x=list(range(len(hist['val_loss']))), y=hist['val_loss'], mode='lines+markers', name='Val Loss'), row=1, col=1 )\n",
    "\n",
    "# Precision\n",
    "fig_metrics.add_trace(  go.Scatter(x=list(range(len(hist['precision']))), y=hist['precision'],  mode='lines+markers', name=f'Train precision'),  row=1, col=2 )\n",
    "fig_metrics.add_trace( go.Scatter(x=list(range(len(hist['val_precision']))), y=hist['val_precision'], mode='lines+markers', name=f'Val precision'), row=1, col=2)\n",
    "\n",
    "# Accuracy\n",
    "fig_metrics.add_trace(  go.Scatter(x=list(range(len(hist['accuracy']))), y=hist['accuracy'],  mode='lines+markers', name=f'Train accuracy'),  row=2, col=1 )\n",
    "fig_metrics.add_trace( go.Scatter(x=list(range(len(hist['val_accuracy']))), y=hist['val_accuracy'], mode='lines+markers', name=f'Val accuracy'), row=2, col=1)\n",
    "\n",
    "# Recall\n",
    "fig_metrics.add_trace(  go.Scatter(x=list(range(len(hist['recall']))), y=hist['recall'],  mode='lines+markers', name=f'Train recall'),  row=2, col=2 )\n",
    "fig_metrics.add_trace( go.Scatter(x=list(range(len(hist['val_recall']))), y=hist['val_recall'], mode='lines+markers', name=f'Val recall'), row=2, col=2)\n",
    "\n",
    "# fig.update_xaxes(title_text=\"Epochs\", row=1, col=1)\n",
    "fig_metrics.update_yaxes(title_text=\"Loss\", row=1, col=1)\n",
    "fig_metrics.update_yaxes(title_text=f\"Precision\", row=1, col=2)\n",
    "fig_metrics.update_yaxes(title_text=f\"Accuracy\", row=2, col=1)\n",
    "fig_metrics.update_yaxes(title_text=f\"Recall\", row=2, col=2)\n",
    "\n",
    "fig_metrics.update_layout(\n",
    "    # title_text=\"Training and validation metrics over epochs\",\n",
    "    showlegend=True,\n",
    "    margin=dict(l=10, r=10, b=10, t=30),\n",
    "    width=1400, height=800\n",
    ")\n",
    "\n",
    "for annotation in fig_metrics['layout']['annotations']:\n",
    "    annotation['y'] = annotation['y'] + 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "test_loss, test_acc, test_prec, test_recall = custom_MobileNet.evaluate(\n",
    "    test_generator,\n",
    "    steps=test_generator.samples // test_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = test_generator.classes\n",
    "y_pred = custom_MobileNet.predict(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "# y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "y_true = y_true[:len(y_pred_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true.shape, y_pred_classes.shape, test_generator.class_indices.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Plotly heatmap for confusion matrix\n",
    "fig_confMatrix = go.Figure(data=go.Heatmap(\n",
    "    z=cm,\n",
    "    x= class_labels ,   # Predicted labels\n",
    "    y= class_labels,    # True labels\n",
    "    hoverongaps=False,\n",
    "    colorscale='Blues',\n",
    "    showscale=True,\n",
    "    text=cm,\n",
    "    texttemplate=\"%{text}\",\n",
    "    textfont={\"size\":15}\n",
    "))\n",
    "\n",
    "# Update layout to add labels and title\n",
    "fig_confMatrix.update_layout(\n",
    "    title='Confusion Matrix',\n",
    "    xaxis_title='Predicted Label',\n",
    "    yaxis_title='True Label',\n",
    "    width=600,\n",
    "    height=500,\n",
    ")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "# Compute ROC curve and ROC AUC\n",
    "fpr, tpr, _ = roc_curve(y_true, y_pred_classes)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve using Plotly\n",
    "fig_rocauc = go.Figure()\n",
    "\n",
    "# Add the ROC curve\n",
    "fig_rocauc.add_trace(go.Scatter(\n",
    "    x=fpr, y=tpr,\n",
    "    mode='lines',\n",
    "    line=dict(color='blue', width=2),\n",
    "    name=f'ROC curve (AUC = {roc_auc:0.2f})'\n",
    "))\n",
    "\n",
    "# Add the diagonal line (random classifier)\n",
    "fig_rocauc.add_trace(go.Scatter(\n",
    "    x=[0, 1], y=[0, 1],\n",
    "    mode='lines',\n",
    "    line=dict(color='black', dash='dash'),\n",
    "    showlegend=False,\n",
    "    hoverinfo='skip'\n",
    "))\n",
    "\n",
    "# Update layout with axis titles and legend\n",
    "fig_rocauc.update_layout(\n",
    "    title='ROC AUC for Binary Classification',\n",
    "    xaxis_title='False Positive Rate',\n",
    "    yaxis_title='True Positive Rate',\n",
    "    width=700,\n",
    "    height=600,\n",
    "    legend=dict(x=0.6, y=0.1),\n",
    "    margin=dict(l=40, r=40, t=40, b=40),)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_true, y_pred_classes, target_names=class_labels, \n",
    "                               zero_division=False,\n",
    "                               labels = [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation plots+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(hist)\n",
    "# hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=4, cols=2, \n",
    "    subplot_titles=(\"\", \"\",\n",
    "                    \"Loss\", \"Precision\", \n",
    "                    \"Accuracy\", 'Recall',\n",
    "                    'Confusion Matrix', 'ROC-AUC curve'), \n",
    "    horizontal_spacing=0.05, \n",
    "    vertical_spacing=0.05  \n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0.5], y=[0.5], \n",
    "        text=[\n",
    "            top_layers_text\n",
    "        ],\n",
    "        mode='text',\n",
    "        showlegend=False,\n",
    "    ),\n",
    "    row=1, col=1  \n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0.5], y=[0.5], \n",
    "        text=[\n",
    "            f\"Test loss: {test_loss:.4f}<br>\"\n",
    "            f\"Test accuracy: {test_acc:.4f}<br>\"\n",
    "            f\"Test precision: {test_prec:.4f}<br>\"\n",
    "            f\"Test recall: {test_recall:.4f}<br><br>\"\n",
    "            f\"ROC-AUC: {roc_auc:.4f}<br><br>\"\n",
    "            f\"Classification report<br>\"\n",
    "            f\"{report.replace('\\n','<br>')}\"\n",
    "        ],\n",
    "        mode='text',\n",
    "        showlegend=False,\n",
    "    ),\n",
    "    row=1, col=2  \n",
    ")\n",
    "\n",
    "\n",
    "# fig.update_layout(\n",
    "#     annotations=[dict(text=\"Model Metrics\", x=0.25, y=1.05, showarrow=False, xref=\"paper\", yref=\"paper\", font=dict(size=16))], \n",
    "# )\n",
    "\n",
    "# Hide the axes for the annotation row\n",
    "fig.update_xaxes(visible=False, row=1, col=1)\n",
    "fig.update_yaxes(visible=False, row=1, col=1)\n",
    "\n",
    "\n",
    "# Loss and Precision\n",
    "fig.add_trace(fig_metrics['data'][0], row=2, col=1)\n",
    "fig.add_trace(fig_metrics['data'][1], row=2, col=1)\n",
    "fig.add_trace(fig_metrics['data'][2], row=2, col=2)\n",
    "fig.add_trace(fig_metrics['data'][3], row=2, col=2)\n",
    "\n",
    "# Accuracy and Recall \n",
    "fig.add_trace(fig_metrics['data'][4], row=3, col=1)\n",
    "fig.add_trace(fig_metrics['data'][5], row=3, col=1)\n",
    "fig.add_trace(fig_metrics['data'][6], row=3, col=2)\n",
    "fig.add_trace(fig_metrics['data'][7], row=3, col=2)\n",
    "\n",
    "# Confusion Matrix and ROC-AUC curve \n",
    "fig.add_trace(fig_confMatrix['data'][0], row=4, col=1)\n",
    "fig.add_trace(fig_rocauc['data'][0], row=4, col=2)\n",
    "fig.add_trace(fig_rocauc['data'][1], row=4, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=400*4, \n",
    "    width=1400, \n",
    "    # title_text=f\"--- {MODEL.name} ---\",\n",
    "    showlegend=False, \n",
    "    margin=dict(l=10, r=10, t=50, b=10),  \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1  # TODO add file checking for n+1\n",
    "custom_MobileNet.save(f'{MODEL.name}_{n:02}.h5')\n",
    "custom_MobileNet.save(f'{MODEL.name}_{n:02}.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
