{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pandas numpy scikit-learn plotly matplotlib\n",
    "# ! pip install nbformat\n",
    "# ! pip install --upgrade nbformat\n",
    "# ! pip install tensorflow[and-cuda]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 09:32:11.614223: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-21 09:32:11.624547: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-21 09:32:11.627678: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-21 09:32:11.636313: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-21 09:32:12.465512: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datetime import datetime as dt\n",
    "import glob\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.keras.applications import VGG16, VGG19\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Rescaling, Conv2D, MaxPooling2D, Flatten, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.metrics import Precision, Recall, F1Score\n",
    "import visualkeras\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1729495933.934746   16721 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729495933.975766   16721 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729495933.976150   16721 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "# Check if GPUs are available for training \n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729495933.999160   16721 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729495933.999427   16721 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729495933.999615   16721 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729495934.059212   16721 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729495934.059404   16721 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729495934.059560   16721 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-21 09:32:14.059681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 291 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:06:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "DATASET_FOLDER_TRAIN = 'CIFAKE/train'\n",
    "DATASET_FOLDER_TEST = 'CIFAKE/test'\n",
    "\n",
    "BATCH_SIZE = 24\n",
    "COLOR_MODE = 'grayscale'\n",
    "CLASS_MODE = 'binary'\n",
    "TARGET_SIZE = (32, 32)\n",
    "LEARN_RATE = 0.0005\n",
    "SEED = 42\n",
    "\n",
    "N_EPOCHS = 30\n",
    "MODEL = VGG16(weights='imagenet', include_top=False, input_shape=(32,32,3))      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'CIFAKE/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m train_datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(\n\u001b[1;32m      2\u001b[0m     rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m,  \n\u001b[1;32m      3\u001b[0m     rotation_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m45\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m,  \n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Load training data from directory and apply transformations\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_datagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mDATASET_FOLDER_TRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTARGET_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCOLOR_MODE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCLASS_MODE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSEED\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Load validation data (20% of the training data)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m validation_generator \u001b[38;5;241m=\u001b[39m train_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[1;32m     25\u001b[0m     DATASET_FOLDER_TRAIN, \n\u001b[1;32m     26\u001b[0m     target_size\u001b[38;5;241m=\u001b[39mTARGET_SIZE,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     32\u001b[0m )\n",
      "File \u001b[0;32m/mnt/sde1/My_Files/Code/Git_Repos/hve_projects/.venv/lib/python3.12/site-packages/keras/src/legacy/preprocessing/image.py:1138\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow_from_directory\u001b[39m(\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1122\u001b[0m     directory,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     keep_aspect_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1137\u001b[0m ):\n\u001b[0;32m-> 1138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDirectoryIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/sde1/My_Files/Code/Git_Repos/hve_projects/.venv/lib/python3.12/site-packages/keras/src/legacy/preprocessing/image.py:453\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[1;32m    452\u001b[0m     classes \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 453\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[1;32m    455\u001b[0m             classes\u001b[38;5;241m.\u001b[39mappend(subdir)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'CIFAKE/train'"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  \n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.5,\n",
    "    height_shift_range=0.5,\n",
    "    zoom_range=0.5,\n",
    "    horizontal_flip=True,  \n",
    "    vertical_flip=True,  \n",
    "    validation_split=0.3,  \n",
    ")\n",
    "\n",
    "# Load training data from directory and apply transformations\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    DATASET_FOLDER_TRAIN,  \n",
    "    target_size=TARGET_SIZE,    \n",
    "    color_mode=COLOR_MODE,  \n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=CLASS_MODE,  \n",
    "    subset='training', \n",
    "    seed = SEED\n",
    ")\n",
    "\n",
    "# Load validation data (20% of the training data)\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    DATASET_FOLDER_TRAIN, \n",
    "    target_size=TARGET_SIZE,\n",
    "    color_mode=COLOR_MODE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=CLASS_MODE,\n",
    "    subset='validation', \n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    DATASET_FOLDER_TEST,  \n",
    "    target_size=TARGET_SIZE,\n",
    "    color_mode=COLOR_MODE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=CLASS_MODE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Class distribution: ')\n",
    "print( f'Train REAL images: {len(glob.glob('CIFAKE/train/REAL/*'))}'  )\n",
    "print( f'Train FAKE images: {len(glob.glob('CIFAKE/train/FAKE/*'))}'  )\n",
    "\n",
    "print( f'Test REAL images: {len(glob.glob('CIFAKE/test/REAL/*'))}'  )\n",
    "print( f'Test FAKE images: {len(glob.glob('CIFAKE/test/FAKE/*'))}'  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show random image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to rgb\n",
    "def convert_grayscale_to_rgb(batch):\n",
    "    tensor_batch = tf.convert_to_tensor(batch)\n",
    "\n",
    "    rgb_batch = tf.image.grayscale_to_rgb(tensor_batch)\n",
    "    return rgb_batch\n",
    "\n",
    "def rgb_wrapper(generator):\n",
    "    for batch, labels in generator:\n",
    "        yield convert_grayscale_to_rgb(batch), labels\n",
    "\n",
    "train_generator_rgb = rgb_wrapper(train_generator)\n",
    "validation_generator_rgb = rgb_wrapper(validation_generator)\n",
    "test_generator_rgb = rgb_wrapper(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_layers_text = \"x = Flatten()(VGG_model.output)<br>\"\n",
    "top_layers_text += \"x = Dense(32, activation='relu')(x)<br>\"\n",
    "# top_layers_text += \"x = BatchNormalization()(x)<br>\"\n",
    "top_layers_text += \"x = Dense(32, activation='relu')(x)<br>\"\n",
    "top_layers_text += \"x = Dense(1, activation='sigmoid')(x)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = train_generator.num_classes\n",
    "\n",
    "VGG_model = MODEL\n",
    "\n",
    "for layer in VGG_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = Flatten()(VGG_model.output)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Custom model\n",
    "customVGG = Model(inputs=VGG_model.input, outputs=x)\n",
    "\n",
    "customVGG.compile(loss=BinaryCrossentropy(), \n",
    "                  optimizer=Adam(learning_rate=LEARN_RATE), \n",
    "                  metrics=['accuracy', Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = customVGG.fit(train_generator_rgb, \n",
    "                             callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)],\n",
    "                             epochs=N_EPOCHS, \n",
    "                             validation_data=validation_generator_rgb,\n",
    "                             steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "                             validation_steps=validation_generator.samples // BATCH_SIZE,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history.history\n",
    "cols = list(history.history.keys())\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = int(cols[3][-1])\n",
    "\n",
    "# dict_ = { 'loss' : hist['loss'],\n",
    "#          'accuracy' : hist[f'accuracy'],\n",
    "#          'precision' : hist[f'precision_{n}'],\n",
    "#          'recall' : hist[f'recall_{n}'],\n",
    "#          'val_loss' : hist['val_loss'],\n",
    "#          'val_accuracy' : hist[f'val_accuracy'],\n",
    "#          'val_precision' : hist[f'val_precision_{n}'],\n",
    "#          'val_recall' : hist[f'val_recall_{n}']\n",
    "\n",
    "# }\n",
    "# hist = pd.DataFrame(dict_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_metrics = make_subplots(rows=2, cols=2, subplot_titles=(\"Loss\", f\"Precision\", \"Accuracy\", \"Recall\"), vertical_spacing=0.07)\n",
    "\n",
    "# Loss\n",
    "fig_metrics.add_trace( go.Scatter(x=list(range(len(hist['loss']))), y=hist['loss'], mode='lines+markers', name='Train Loss'), row=1, col=1 )\n",
    "fig_metrics.add_trace( go.Scatter(x=list(range(len(hist['val_loss']))), y=hist['val_loss'], mode='lines+markers', name='Val Loss'), row=1, col=1 )\n",
    "\n",
    "# Precision\n",
    "fig_metrics.add_trace(  go.Scatter(x=list(range(len(hist['precision']))), y=hist['precision'],  mode='lines+markers', name=f'Train precision'),  row=1, col=2 )\n",
    "fig_metrics.add_trace( go.Scatter(x=list(range(len(hist['val_precision']))), y=hist['val_precision'], mode='lines+markers', name=f'Val precision'), row=1, col=2)\n",
    "\n",
    "# Accuracy\n",
    "fig_metrics.add_trace(  go.Scatter(x=list(range(len(hist['accuracy']))), y=hist['accuracy'],  mode='lines+markers', name=f'Train accuracy'),  row=2, col=1 )\n",
    "fig_metrics.add_trace( go.Scatter(x=list(range(len(hist['val_accuracy']))), y=hist['val_accuracy'], mode='lines+markers', name=f'Val accuracy'), row=2, col=1)\n",
    "\n",
    "# Recall\n",
    "fig_metrics.add_trace(  go.Scatter(x=list(range(len(hist['recall']))), y=hist['recall'],  mode='lines+markers', name=f'Train recall'),  row=2, col=2 )\n",
    "fig_metrics.add_trace( go.Scatter(x=list(range(len(hist['val_recall']))), y=hist['val_recall'], mode='lines+markers', name=f'Val recall'), row=2, col=2)\n",
    "\n",
    "# fig.update_xaxes(title_text=\"Epochs\", row=1, col=1)\n",
    "fig_metrics.update_yaxes(title_text=\"Loss\", row=1, col=1)\n",
    "fig_metrics.update_yaxes(title_text=f\"Precision\", row=1, col=2)\n",
    "fig_metrics.update_yaxes(title_text=f\"Accuracy\", row=2, col=1)\n",
    "fig_metrics.update_yaxes(title_text=f\"Recall\", row=2, col=2)\n",
    "\n",
    "fig_metrics.update_layout(\n",
    "    # title_text=\"Training and validation metrics over epochs\",\n",
    "    showlegend=True,\n",
    "    margin=dict(l=10, r=10, b=10, t=30),\n",
    "    width=1400, height=800\n",
    ")\n",
    "\n",
    "for annotation in fig_metrics['layout']['annotations']:\n",
    "    annotation['y'] = annotation['y'] + 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "test_loss, test_acc, test_prec, test_recall = customVGG.evaluate(\n",
    "    test_generator_rgb,\n",
    "    steps=test_generator.samples // test_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = test_generator.classes\n",
    "y_pred = customVGG.predict(test_generator_rgb, steps=test_generator.samples // test_generator.batch_size)\n",
    "# y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "y_true = y_true[:len(y_pred_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true.shape, y_pred_classes.shape, test_generator.class_indices.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Plotly heatmap for confusion matrix\n",
    "fig_confMatrix = go.Figure(data=go.Heatmap(\n",
    "    z=cm,\n",
    "    x=['REAL', 'FAKE'] ,  # Predicted labels\n",
    "    y= class_labels,  # True labels\n",
    "    hoverongaps=False,\n",
    "    colorscale='Blues',\n",
    "    showscale=True,\n",
    "    text=cm,\n",
    "    texttemplate=\"%{text}\",\n",
    "    textfont={\"size\":15}\n",
    "))\n",
    "\n",
    "# Update layout to add labels and title\n",
    "fig_confMatrix.update_layout(\n",
    "    title='Confusion Matrix',\n",
    "    xaxis_title='Predicted Label',\n",
    "    yaxis_title='True Label',\n",
    "    width=600,\n",
    "    height=500,\n",
    ")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "# Compute ROC curve and ROC AUC\n",
    "fpr, tpr, _ = roc_curve(y_true, y_pred_classes)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve using Plotly\n",
    "fig_rocauc = go.Figure()\n",
    "\n",
    "# Add the ROC curve\n",
    "fig_rocauc.add_trace(go.Scatter(\n",
    "    x=fpr, y=tpr,\n",
    "    mode='lines',\n",
    "    line=dict(color='blue', width=2),\n",
    "    name=f'ROC curve (AUC = {roc_auc:0.2f})'\n",
    "))\n",
    "\n",
    "# Add the diagonal line (random classifier)\n",
    "fig_rocauc.add_trace(go.Scatter(\n",
    "    x=[0, 1], y=[0, 1],\n",
    "    mode='lines',\n",
    "    line=dict(color='black', dash='dash'),\n",
    "    showlegend=False,\n",
    "    hoverinfo='skip'\n",
    "))\n",
    "\n",
    "# Update layout with axis titles and legend\n",
    "fig_rocauc.update_layout(\n",
    "    title='ROC AUC for Binary Classification',\n",
    "    xaxis_title='False Positive Rate',\n",
    "    yaxis_title='True Positive Rate',\n",
    "    width=700,\n",
    "    height=600,\n",
    "    legend=dict(x=0.6, y=0.1),\n",
    "    margin=dict(l=40, r=40, t=40, b=40),)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_true, y_pred_classes, target_names=class_labels, \n",
    "                               zero_division=False,\n",
    "                               labels = [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation plots+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(hist)\n",
    "# hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=4, cols=2, \n",
    "    subplot_titles=(\"\", \"\",\n",
    "                    \"Loss\", \"Precision\", \n",
    "                    \"Accuracy\", 'Recall',\n",
    "                    'Confusion Matrix', 'ROC-AUC curve'), \n",
    "    horizontal_spacing=0.05, \n",
    "    vertical_spacing=0.05  \n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0.5], y=[0.5], \n",
    "        text=[\n",
    "            top_layers_text\n",
    "        ],\n",
    "        mode='text',\n",
    "        showlegend=False,\n",
    "    ),\n",
    "    row=1, col=1  \n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0.5], y=[0.5], \n",
    "        text=[\n",
    "            f\"Test loss: {test_loss:.4f}<br>\"\n",
    "            f\"Test accuracy: {test_acc:.4f}<br>\"\n",
    "            f\"Test precision: {test_prec:.4f}<br>\"\n",
    "            f\"Test recall: {test_recall:.4f}<br><br>\"\n",
    "            f\"ROC-AUC: {roc_auc:.4f}<br><br>\"\n",
    "            f\"Classification report<br>\"\n",
    "            f\"{report.replace('\\n','<br>')}\"\n",
    "        ],\n",
    "        mode='text',\n",
    "        showlegend=False,\n",
    "    ),\n",
    "    row=1, col=2  \n",
    ")\n",
    "\n",
    "\n",
    "# fig.update_layout(\n",
    "#     annotations=[dict(text=\"Model Metrics\", x=0.25, y=1.05, showarrow=False, xref=\"paper\", yref=\"paper\", font=dict(size=16))], \n",
    "# )\n",
    "\n",
    "# Hide the axes for the annotation row\n",
    "fig.update_xaxes(visible=False, row=1, col=1)\n",
    "fig.update_yaxes(visible=False, row=1, col=1)\n",
    "\n",
    "\n",
    "# Loss and Precision\n",
    "fig.add_trace(fig_metrics['data'][0], row=2, col=1)\n",
    "fig.add_trace(fig_metrics['data'][1], row=2, col=1)\n",
    "fig.add_trace(fig_metrics['data'][2], row=2, col=2)\n",
    "fig.add_trace(fig_metrics['data'][3], row=2, col=2)\n",
    "\n",
    "# Accuracy and Recall \n",
    "fig.add_trace(fig_metrics['data'][4], row=3, col=1)\n",
    "fig.add_trace(fig_metrics['data'][5], row=3, col=1)\n",
    "fig.add_trace(fig_metrics['data'][6], row=3, col=2)\n",
    "fig.add_trace(fig_metrics['data'][7], row=3, col=2)\n",
    "\n",
    "# Confusion Matrix and ROC-AUC curve \n",
    "fig.add_trace(fig_confMatrix['data'][0], row=4, col=1)\n",
    "fig.add_trace(fig_rocauc['data'][0], row=4, col=2)\n",
    "fig.add_trace(fig_rocauc['data'][1], row=4, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=400*4, \n",
    "    width=1400, \n",
    "    title_text=f\"--- {MODEL.name} ---\",\n",
    "    showlegend=False, \n",
    "    margin=dict(l=10, r=10, t=50, b=10),  \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n=1  # TODO add file checking for n+1\n",
    "customVGG.save(f'{MODEL.name}_{n:02}.h5')\n",
    "customVGG.save(f'{MODEL.name}_{n:02}.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
