{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/examples/vision/grad_cam/#setup\n",
    "# https://dmitry.ai/t/topic/50/2\n",
    "# Check Lambda Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 18:11:02.504125: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 18:11:02.515288: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 18:11:02.518793: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 18:11:02.528937: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 18:11:03.198355: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# Display\n",
    "from IPython.display import Image, display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import pandas as pd\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow.keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Conv2D, Flatten\n",
    "from tensorflow.keras import regularizers\n",
    "from IPython.display import Image\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n",
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730913065.539461   25272 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730913066.054467   25272 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730913066.054763   25272 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = r'test_img.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1730913066.115091   25272 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730913066.115404   25272 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730913066.115626   25272 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730913066.219652   25272 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730913066.219850   25272 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730913066.220027   25272 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-06 18:11:06.220159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 150 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:06:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('models/GridSearch_customModel.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x74872d80eab0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load img\n",
    "img = image.load_img(img_path, target_size=(32, 32))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 32, 32, 3), numpy.ndarray)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = image.img_to_array(img)\n",
    "img = preprocess_input(img, data_format=None)\n",
    "img = img/255.0\n",
    "\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img.shape, type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730913067.114447   25339 service.cc:146] XLA service 0x748610006170 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1730913067.114467   25339 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce GTX 1060 6GB, Compute Capability 6.1\n",
      "2024-11-06 18:11:07.120356: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-06 18:11:07.192764: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 910ms/step\n",
      "REAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 18:11:07.847658: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 85.06MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-06 18:11:07.854761: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 52.84MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "I0000 00:00:1730913067.978508   25339 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "img_pred = model.predict(img)\n",
    "img_pred_class = 'FAKE' if img_pred < 0.5 else 'REAL'\n",
    "print(img_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_41\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_41\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4608</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">110,616</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling_41 (\u001b[38;5;33mRescaling\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_82 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m3,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_82 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_83 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_83 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_41 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4608\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_82 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │       \u001b[38;5;34m110,616\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_41 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_83 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m25\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">785,429</span> (3.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m785,429\u001b[0m (3.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">261,809</span> (1022.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m261,809\u001b[0m (1022.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">523,620</span> (2.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m523,620\u001b[0m (2.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1730913125.326989   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.351251   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.352355   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.353457   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.355032   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.358437   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.360007   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.361121   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.362239   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.363359   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.364462   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.365580   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.366790   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.465767   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.466952   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.468060   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.469230   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.470414   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.472086   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.475754   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.477041   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.478210   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.479431   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.480661   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.481880   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.483125   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.484362   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.485519   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.486770   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.488185   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.492145   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.493476   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.494771   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.606850   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913125.610754   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.139889   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.141672   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.143657   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.144821   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.146056   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.147395   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.148640   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.193943   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.195491   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.196597   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.197703   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.200044   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.201179   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.202314   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.203451   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.208061   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.209287   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.213697   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.214875   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.216061   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.222302   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.225129   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.226239   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.227344   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.228541   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.229756   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.231050   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.232409   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.234562   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.235694   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.236857   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.238466   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.242010   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.243156   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.244315   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1730913126.245497   25272 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m last_conv_layer_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv2d_83\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     40\u001b[0m last_layer_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdense_83\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 41\u001b[0m heatmap \u001b[38;5;241m=\u001b[39m \u001b[43mmake_gradcam_heatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_conv_layer_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_layer_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m heatmap\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# plt.matshow(heatmap)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 25\u001b[0m, in \u001b[0;36mmake_gradcam_heatmap\u001b[0;34m(img_array, model, last_conv_layer_name, last_layer_name, pred_index)\u001b[0m\n\u001b[1;32m     21\u001b[0m grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(class_channel, last_conv_layer_output)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# # This is a vector where each entry is the mean intensity of the gradient\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# # over a specific feature map channel\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m pooled_grads \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# We multiply each channel in the feature map array\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# by \"how important this channel is\" with regard to the top predicted class\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# then sum all the channels to obtain the heatmap class activation\u001b[39;00m\n\u001b[1;32m     30\u001b[0m last_conv_layer_output \u001b[38;5;241m=\u001b[39m last_conv_layer_output[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/media/rasna/LinsT7_ExtSSD/My_Files/Code/Git_Repos/hve_projects/.venv/lib/python3.12/site-packages/tensorflow/python/ops/weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     87\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     90\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m/media/rasna/LinsT7_ExtSSD/My_Files/Code/Git_Repos/hve_projects/.venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/media/rasna/LinsT7_ExtSSD/My_Files/Code/Git_Repos/hve_projects/.venv/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, last_layer_name, pred_index=None):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "\n",
    "\n",
    "    grad_model = keras.models.Model(\n",
    "        model.inputs, [model.get_layer(last_conv_layer_name).output, model.get_layer(last_layer_name).output]\n",
    "    )\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)  \n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "# VGG\n",
    "last_conv_layer_name = 'conv2d_83'\n",
    "last_layer_name = 'dense_83'\n",
    "heatmap = make_gradcam_heatmap(img, model, last_conv_layer_name, last_layer_name, pred_index=0)\n",
    "\n",
    "heatmap\n",
    "# plt.matshow(heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Show heatmap on img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
    "    # Load the original image\n",
    "    img = keras.utils.load_img(img_path)\n",
    "    img = keras.utils.img_to_array(img)\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Use jet colormap to colorize heatmap\n",
    "    jet = mpl.colormaps[\"jet\"]\n",
    "\n",
    "    # Use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = keras.utils.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = keras.utils.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = keras.utils.array_to_img(superimposed_img)\n",
    "\n",
    "    # Save the superimposed image\n",
    "    superimposed_img.save(cam_path)\n",
    "\n",
    "    # Display Grad CAM\n",
    "    display(Image(cam_path))\n",
    "\n",
    "\n",
    "save_and_display_gradcam(img_path, heatmap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
